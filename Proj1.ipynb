{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2868874\n",
      "Epoch 0,Train loss 2.1219829979455076,Test loss 2.092039894454087,Final acc 0.3626\n",
      "Epoch 1,Train loss 1.9886822066343655,Test loss 2.0197547447832327,Final acc 0.4322\n",
      "Epoch 2,Train loss 1.8914640407123224,Test loss 1.8787319780905036,Final acc 0.5871\n",
      "Epoch 3,Train loss 1.841606229162582,Test loss 1.8979330606098417,Final acc 0.5607\n",
      "Epoch 4,Train loss 1.806178295094034,Test loss 1.8457725742195226,Final acc 0.6181\n",
      "Epoch 5,Train loss 1.7749960574957415,Test loss 1.8510072020035755,Final acc 0.6125\n",
      "Epoch 6,Train loss 1.7472906884025126,Test loss 1.7654166236708435,Final acc 0.6959\n",
      "Epoch 7,Train loss 1.7290813547875874,Test loss 1.824456101731409,Final acc 0.6383\n",
      "Epoch 8,Train loss 1.7192171751080876,Test loss 1.7575609880157663,Final acc 0.7064\n",
      "Epoch 9,Train loss 1.7082259993419013,Test loss 1.73013076752047,Final acc 0.7397\n",
      "Epoch 10,Train loss 1.6461067044216653,Test loss 1.6301151604592046,Final acc 0.8352\n",
      "Epoch 11,Train loss 1.6268855693090298,Test loss 1.6196135086349295,Final acc 0.8474\n",
      "Epoch 12,Train loss 1.6186970435749843,Test loss 1.6187931766992882,Final acc 0.8505\n",
      "Epoch 13,Train loss 1.609885452653441,Test loss 1.6130346180517463,Final acc 0.8528\n",
      "Epoch 14,Train loss 1.6036328403541193,Test loss 1.6113955853860589,Final acc 0.8564\n",
      "Epoch 15,Train loss 1.5978902819211527,Test loss 1.6078810420217393,Final acc 0.859\n",
      "Epoch 16,Train loss 1.594993301669655,Test loss 1.606801921808267,Final acc 0.8602\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 254\u001b[0m\n\u001b[0;32m    252\u001b[0m     fit\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    253\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 254\u001b[0m     train_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mfit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader_test):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "def get_data(path, leng_data):\n",
    "    dataset = unpickle(path)\n",
    "    data_x = [data for index, data in enumerate(dataset[b'data'])]\n",
    "    data_x = np.array(data_x)\n",
    "    data_y = [data for index, data in enumerate(dataset[b'labels'])]\n",
    "    data_y = np.array(data_y)\n",
    "    # print(data_x.shape)\n",
    "    # print(data_y.shape)\n",
    "    \n",
    "    data_x_red=data_x[0:leng_data,0:1024]\n",
    "    data_x_green=data_x[0:leng_data,1024:2048]\n",
    "    data_x_blue=data_x[0:leng_data,2048:]\n",
    "\n",
    "    red=data_x_red.reshape(len(data_x_red),32,32)\n",
    "    green=data_x_green.reshape(len(data_x_green),32,32)\n",
    "    blue=data_x_blue.reshape(len(data_x_blue),32,32)\n",
    "\n",
    "    sample=np.stack([red, green, blue], axis=1)\n",
    "    sample=sample.astype(np.float32) / 255.0\n",
    "    sample=sample.reshape(len(sample),3,32,32)\n",
    "    # print(len(sample))\n",
    "    label=data_y[0:leng_data]\n",
    "    # print(sample.shape)\n",
    "    # print(label.shape)\n",
    "    \n",
    "    return sample, label\n",
    "\n",
    "class block(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(block, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), stride=stride, padding=(1, 1), bias=False)\n",
    "        self.Bn1 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.Ru = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=(1, 1), bias=False)\n",
    "        self.Bn2 = torch.nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.connection = torch.nn.Identity()\n",
    "        if in_channels != out_channels:\n",
    "            self.connection = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                torch.nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.connection = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(out_channels, out_channels, kernel_size=(1, 1), stride=1, bias=False),\n",
    "                torch.nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.connection(x)\n",
    "        x = self.Ru(self.Bn1(self.conv1(x)))\n",
    "        x = self.Bn2(self.conv2(x)) + identity\n",
    "        return self.Ru(x)\n",
    "    \n",
    "class layers(torch.nn.Module):\n",
    "    def __init__(self, layer, in_channels, out_channels, stride):\n",
    "        super(layers,self).__init__()\n",
    "        self.layer=layer\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        self.stride=stride\n",
    "        self.Layer = self._Layer()\n",
    "    def _Layer(self):\n",
    "        layers=[]\n",
    "        for _ in range(self.layer):\n",
    "            layers.append(block(self.in_channels, self.out_channels, self.stride))\n",
    "            self.in_channels=self.out_channels\n",
    "            self.stride=1\n",
    "        return torch.nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.Layer(x)        \n",
    "\n",
    "class Resnet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.in_channel = 3\n",
    "        self.kernel_size=(3,3)\n",
    "        self.stride = [1,2]\n",
    "        self.padding = (1, 1)\n",
    "        self.kernel_size1=(7,7)\n",
    "        self.padding2 = (3, 3)\n",
    "        self.Ci = [64, 128, 256, 512]\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=self.in_channel, out_channels=self.Ci[0], kernel_size=self.kernel_size, stride=self.stride[0], padding=self.padding, bias=True)\n",
    "        # self.conv1 = torch.nn.Conv2d(in_channels=self.in_channel, out_channels=self.Ci[0], kernel_size=self.kernel_size1, stride=self.stride[1], padding=self.padding2, bias=False)\n",
    "        self.ReLU = torch.nn.ReLU(inplace=True)\n",
    "        self.BN = torch.nn.BatchNorm2d(self.Ci[0],eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.Averagepool2=torch.nn.MaxPool2d(kernel_size=self.kernel_size, stride=self.stride[1], padding=self.padding, dilation=1, ceil_mode=False)  \n",
    "        \n",
    "        self.layer1=layers(2,self.Ci[0], self.Ci[0], stride=self.stride[0])\n",
    "        self.layer2=layers(2,self.Ci[0], self.Ci[1], stride=self.stride[1])\n",
    "        self.layer3=layers(2,self.Ci[1], self.Ci[2], stride=self.stride[1])\n",
    "        # self.layer4=layers(2,self.Ci[2], self.Ci[3], stride=self.stride[1])\n",
    "\n",
    "        self.layer_pick=self.Ci[2]\n",
    "        \n",
    "        self.fc = torch.nn.Linear(self.layer_pick, 10, bias=True) \n",
    "        \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.Averagepool=torch.nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.ReLU(self.BN(self.conv1(x)))\n",
    "        # x = self.Averagepool2(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "\n",
    "        x = self.Averagepool(x)\n",
    "\n",
    "        x = x.view(-1,self.layer_pick)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# from torchvision import datasets, models, transforms\n",
    "# model = models.resnet34(pretrained=True).cuda()\n",
    "\n",
    "model=Resnet().cuda()\n",
    "loss=torch.nn.CrossEntropyLoss()\n",
    "#opt = torch.optim.Adam(model.parameters(), lr=0.001, betas=[0.9,0.999],eps=1e-8)\n",
    "opt=torch.optim.SGD(model.parameters(),lr=0.1,momentum=0.9 ,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "train_loss_hist=[]\n",
    "test_loss_hist=[]\n",
    "accuracy_hist=[]\n",
    "\n",
    "leng_data=10000\n",
    "\n",
    "path=r\"C:\\Users\\26435\\Desktop\\ECE-Gy Deep\\Code_ex\\Proj\\deep-learning-spring-2025-project-1\\cifar-10-python\\cifar-10-batches-py\\data_batch_1\"\n",
    "path3=r\"C:\\Users\\26435\\Desktop\\ECE-Gy Deep\\Code_ex\\Proj\\deep-learning-spring-2025-project-1\\cifar-10-python\\cifar-10-batches-py\\data_batch_2\"\n",
    "path4=r\"C:\\Users\\26435\\Desktop\\ECE-Gy Deep\\Code_ex\\Proj\\deep-learning-spring-2025-project-1\\cifar-10-python\\cifar-10-batches-py\\data_batch_3\"\n",
    "path5=r\"C:\\Users\\26435\\Desktop\\ECE-Gy Deep\\Code_ex\\Proj\\deep-learning-spring-2025-project-1\\cifar-10-python\\cifar-10-batches-py\\data_batch_4\"\n",
    "path6=r\"C:\\Users\\26435\\Desktop\\ECE-Gy Deep\\Code_ex\\Proj\\deep-learning-spring-2025-project-1\\cifar-10-python\\cifar-10-batches-py\\data_batch_5\"\n",
    "    \n",
    "sample,label=get_data(path,leng_data)\n",
    "batch1_x = torch.tensor(sample)\n",
    "batch1_y = torch.tensor(label)\n",
    "sample,label=get_data(path3,leng_data)\n",
    "batch2_x = torch.tensor(sample)\n",
    "batch2_y = torch.tensor(label)\n",
    "sample,label=get_data(path4,leng_data)\n",
    "batch3_x = torch.tensor(sample)\n",
    "batch3_y = torch.tensor(label)\n",
    "sample,label=get_data(path5,leng_data)\n",
    "batch4_x = torch.tensor(sample)\n",
    "batch4_y = torch.tensor(label)\n",
    "sample,label=get_data(path6,leng_data)\n",
    "batch5_x = torch.tensor(sample)\n",
    "batch5_y = torch.tensor(label)\n",
    "x_tensor = torch.cat([batch1_x, batch2_x,batch3_x,batch4_x,batch5_x], dim=0)\n",
    "y_tensor = torch.cat([batch1_y, batch2_y,batch3_y,batch4_y,batch5_y], dim=0)\n",
    "\n",
    "class transform(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor, transform=None):\n",
    "        self.x_tensor = x_tensor\n",
    "        self.y_tensor = y_tensor\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_tensor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x_tensor[index]\n",
    "        y = self.y_tensor[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "dataset = transform(x_tensor, y_tensor, transform=train_transforms)\n",
    "\n",
    "path2=r\"C:\\Users\\26435\\Desktop\\ECE-Gy Deep\\Code_ex\\Proj\\deep-learning-spring-2025-project-1\\cifar-10-python\\cifar-10-batches-py\\test_batch\"\n",
    "sample,label=get_data(path2,leng_data)\n",
    "x_tensor = torch.tensor(sample)\n",
    "y_tensor = torch.tensor(label)\n",
    "dataset = transform(x_tensor, y_tensor, transform=test_transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "epoch_len=50\n",
    "for edop in range(epoch_len):\n",
    "    train_loss=0.0\n",
    "    test_loss=0.0\n",
    "    correct=0\n",
    "    total_count=0\n",
    "    model.train()\n",
    "    for i,data in enumerate(data_loader):\n",
    "        images,labels=data\n",
    "        images=images.cuda()\n",
    "        labels=labels.long().cuda()\n",
    "        opt.zero_grad()\n",
    "        predict_y=model(images)\n",
    "\n",
    "        fit=loss(predict_y,labels)\n",
    "        fit.backward()\n",
    "        opt.step()\n",
    "        train_loss+=fit.item()\n",
    "        \n",
    "    model.eval()\n",
    "    for i,data in enumerate(data_loader_test):\n",
    "        with torch.no_grad():\n",
    "            images,labels=data\n",
    "            images=images.cuda()\n",
    "            labels=labels.long().cuda()\n",
    "            predict_y=model(images)\n",
    "            predicted_classes = torch.max(predict_y, 1)[1]\n",
    "            fit=loss(predict_y,labels)\n",
    "            test_loss+=fit.item()\n",
    "            correct += (predicted_classes == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "            \n",
    "    scheduler.step()\n",
    "    \n",
    "    final_accuracy=correct/total_count      \n",
    "    \n",
    "    train_loss=train_loss/len(data_loader)\n",
    "    test_loss=test_loss/len(data_loader_test)\n",
    "    accuracy_hist.append(final_accuracy)\n",
    "    train_loss_hist.append(train_loss)\n",
    "    test_loss_hist.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch {edop},Train loss {train_loss},Test loss {test_loss},Final acc {final_accuracy}')\n",
    "\n",
    "plt.figure()  \n",
    "plt.plot(range(epoch_len),train_loss_hist,'-',linewidth=3,label='Train error')\n",
    "plt.plot(range(epoch_len),test_loss_hist,'-',linewidth=3,label='Test error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "plt.figure()  \n",
    "plt.plot(range(epoch_len),accuracy_hist,'-',linewidth=3,label='accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
